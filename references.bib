
@phdthesis{tinael_devresse_analyse_2023,
	address = {Namur},
	title = {Analyse et conception d’un prototype applicatif pour le commerce en vrac},
	language = {fr},
	urldate = {2025-06-22},
	school = {Hénallux - UNamur},
	author = {{Tinaël Devresse}},
	year = {2023},
	keywords = {p38-40},
}

@misc{noauthor_robot_2025,
	title = {Robot {Operating} {System}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://fr.wikipedia.org/w/index.php?title=Robot_Operating_System&oldid=225842070},
	abstract = {Robot Operating System (ROS), est un ensemble d'outils informatiques sous forme de logiciels libres open source, permettant de développer des logiciels pour la robotique. À l'origine, il est développé en 2007 par la société américaine Willow Garage, pour son robot PR2. Son développement est aujourd'hui mené par l'« Open Robotics » (anciennement Open Source Robotics Foundation ou OSRF). En 2024, ROS est utilisé par plus de 1250 entreprises.},
	language = {fr},
	urldate = {2025-06-18},
	journal = {Wikipédia},
	month = may,
	year = {2025},
	note = {Page Version ID: 225842070},
}

@misc{noauthor_mqtt_nodate,
	title = {{MQTT} - {The} {Standard} for {IoT} {Messaging}},
	url = {https://mqtt.org/},
	urldate = {2025-06-18},
}

@misc{cyberbotics_tutorial_nodate,
	title = {Tutorial {E} puck for {ROS2} {Beginners}},
	url = {https://github.com/cyberbotics/webots_ros2/wiki/Tutorial-E-puck-for-ROS2-Beginners},
	abstract = {Webots ROS 2 packages. Contribute to cyberbotics/webots\_ros2 development by creating an account on GitHub.},
	language = {en},
	urldate = {2025-06-18},
	journal = {GitHub},
	author = {{cyberbotics}},
}

@misc{noauthor_ros_nodate,
	title = {{ROS}: {Home}},
	url = {https://www.ros.org/},
	urldate = {2025-06-18},
}

@misc{noauthor_cyberboticsepuck_ros2_2025,
	title = {cyberbotics/epuck\_ros2},
	copyright = {Apache-2.0},
	url = {https://github.com/cyberbotics/epuck_ros2},
	abstract = {ROS2 node for the e-puck robot and its simulation model},
	urldate = {2025-06-18},
	publisher = {Cyberbotics Ltd.},
	month = mar,
	year = {2025},
	note = {original-date: 2020-02-18T07:17:35Z},
	keywords = {e-puck, robot, robotics, ros, ros2, simulation, webots},
}

@misc{gctronic_gctronicepuck_driver_cpp_2024,
	title = {gctronic/epuck\_driver\_cpp},
	url = {https://github.com/gctronic/epuck_driver_cpp},
	abstract = {E-puck ROS node based on roscpp.},
	urldate = {2025-06-18},
	author = {GCtronic},
	month = sep,
	year = {2024},
	note = {original-date: 2015-08-12T13:16:34Z},
}

@misc{klement_replacing_2018,
	title = {Replacing {The} {User} {Story} {With} {The} {Job} {Story}},
	url = {https://jtbd.info/replacing-the-user-story-with-the-job-story-af7cdee10c27},
	abstract = {Too many assumptions are dangerous},
	language = {en},
	urldate = {2025-02-27},
	journal = {Medium},
	author = {Klement, Alan},
	month = jul,
	year = {2018},
}

@misc{noauthor_langage_nodate,
	title = {Le langage d'{Aseba} - {Thymio} \& {Aseba}},
	url = {https://wiki.thymio.org/fr:asebalanguage},
	urldate = {2025-02-27},
}

@misc{alliance_what_2015,
	title = {What does {INVEST} {Stand} {For}? {\textbar} {Agile} {Alliance}},
	shorttitle = {What does {INVEST} {Stand} {For}?},
	url = {https://www.agilealliance.org/glossary/invest/},
	abstract = {INVEST stands for a set of criteria used to assess the quality of a user story. If the story fails to meet one of these criteria, the team may reword it.},
	language = {en-US},
	urldate = {2025-02-27},
	author = {Alliance, Agile},
	month = dec,
	year = {2015},
}

@misc{noauthor_getting_nodate,
	title = {Getting started with {Aseba} - {Thymio} \& {Aseba}},
	url = {http://aseba.wikidot.com/en:gettingstarted},
	urldate = {2025-02-20},
}

@article{vitanza_robot_2019,
	title = {Robot swarms as an educational tool: {The} {Thymio}’s way},
	volume = {16},
	shorttitle = {Robot swarms as an educational tool},
	doi = {10.1177/1729881418825186},
	abstract = {Robotics provides useful tools for educational purposes, allowing to engage students in learning within disparate domains, from computer science and artificial intelligence – traditionally the main domains for educational robotics – to general education, human and social sciences and arts. Robots can be used with different purposes, from being simple tools to be programmed with some specific behaviour, to being peers with whom to engage in a fruitful interaction for a collaborative learning purpose. In this sense, they can also foster learning of transversal skills such as communication and cooperation. In this article, we propose robot swarms as a novel educational tool to target exactly those transversal skills that are difficult to account otherwise. The usage of multiple robots interacting to solve a common problem can support the learning of concepts related to cooperation and collective actions and can make accessible notions about complex systems that are common in physical, biological, economic and social sciences. Additionally, the possibility to interact and participate in the collective behaviour displayed by the robot swarm can strongly increase the comprehension and engagement with the proposed concept. Motivated by this picture, we propose a roadmap for the utilization of swarm robotics for educational purposes, which is hinged on the Thymio robot, a simple but powerful educational robot that presents all the features required for swarm robotics experimentation. We propose two case studies and we substantiate the proposal with preliminary results from a demonstration of robot swarms performed during a recent robotics festival.},
	journal = {International Journal of Advanced Robotic Systems},
	author = {Vitanza, Alessandra and Rossetti, Paolo and Mondada, Francesco and Trianni, Vito},
	month = jan,
	year = {2019},
	pages = {172988141882518},
}

@misc{noauthor_gctronic_nodate,
	title = {{GCtronic} - e-puck2},
	url = {https://www.gctronic.com/e-puck2.php},
	urldate = {2025-02-14},
}

@article{tully_growing_2003,
	title = {Growing {Up} in {Technological} {Worlds}: {How} {Modern} {Technologies} {Shape} the {Everyday} {Lives} of {Young} {People}},
	volume = {23},
	issn = {0270-4676},
	shorttitle = {Growing {Up} in {Technological} {Worlds}},
	url = {https://doi.org/10.1177/0270467603260812},
	doi = {10.1177/0270467603260812},
	abstract = {The purpose of this article is to show how young people typically interact with technology. Young people take up modern technology and incorporate it in their everyday lives more rapidly and more unceremoniously than others. As they make use of technical artifacts, the everyday lives of young people change, as does their perception of society, because it is through the artifacts that relationships with others are organized. The significance of technology in young people’s everyday lives remains largely unexplored. This deficiency clearly contrasts with an information society, the very basis of which is supposed to be the knowledge of its organizing principles. This article reports on recent findings of how clearly defined social relationships disintegrate because of new technologies and on how young people are challenged to put the applications that technology offers to them into new contexts. The idea is to make a subjectively important choice among the large variety of options given. It shows that technology is no longer result but rather experience oriented. One can foresee the considerable consequences not only for politics, education, and technology development but also for research done in the social sciences.},
	language = {en},
	number = {6},
	urldate = {2025-02-19},
	journal = {Bulletin of Science, Technology \& Society},
	author = {Tully, Claus J.},
	month = dec,
	year = {2003},
	note = {Publisher: SAGE Publications Inc},
	pages = {444--456},
}

@misc{noauthor_omnivision_nodate,
	title = {Omnivision {Module} {V3} - {GCtronic} wiki},
	url = {https://www.gctronic.com/doc/index.php?title=Omnivision_Module_V3},
	urldate = {2025-02-19},
}

@misc{noauthor_inertial_2025,
	title = {Inertial measurement unit},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Inertial_measurement_unit&oldid=1267718143},
	abstract = {An inertial measurement unit (IMU) is an electronic device that measures and reports a body's specific force, angular rate, and sometimes the orientation of the body, using a combination of accelerometers, gyroscopes, and sometimes magnetometers. When the magnetometer is included, IMUs are referred to as IMMUs.
IMUs are typically used to maneuver modern vehicles including motorcycles, missiles, aircraft (an attitude and heading reference system), including uncrewed aerial vehicles (UAVs), among many others, and spacecraft, including satellites and landers. Recent developments allow for the production of IMU-enabled GPS devices. An IMU allows a GPS receiver to work when GPS-signals are unavailable, such as in tunnels, inside buildings, or when electronic interference is present.
IMUs are used in VR headsets and smartphones, and also in motion tracked game controllers like the Wii Remote.},
	language = {en},
	urldate = {2025-02-14},
	journal = {Wikipedia},
	month = jan,
	year = {2025},
	note = {Page Version ID: 1267718143},
}

@misc{noauthor_github_nodate,
	title = {{GitHub} - {Mobsya}/blockly: {The} web-based visual programming editor.},
	url = {https://github.com/Mobsya/blockly},
	urldate = {2025-02-11},
}

@misc{noauthor_e-puck2blockly_2024,
	title = {e-puck2/blockly},
	copyright = {Apache-2.0},
	url = {https://github.com/e-puck2/blockly},
	abstract = {The web-based visual programming editor.},
	urldate = {2025-02-11},
	publisher = {e-puck2},
	month = mar,
	year = {2024},
	note = {original-date: 2024-03-08T15:33:40Z},
}

@misc{noauthor_e-puck2monitor_2024,
	title = {e-puck2/monitor},
	copyright = {GPL-3.0},
	url = {https://github.com/e-puck2/monitor},
	abstract = {Multiplatform monitor for e-puck2 robot. Qt project.},
	urldate = {2025-02-11},
	publisher = {e-puck2},
	month = nov,
	year = {2024},
	note = {original-date: 2017-12-22T22:12:43Z},
}

@misc{noauthor_e-puck2aseba_2024,
	title = {e-puck2/aseba},
	copyright = {LGPL-3.0},
	url = {https://github.com/e-puck2/aseba},
	abstract = {Aseba is a set of tools which allow beginners to program robots easily and efficiently. To contact us, please open an issue.},
	urldate = {2025-02-11},
	publisher = {e-puck2},
	month = mar,
	year = {2024},
	note = {original-date: 2024-03-08T15:47:14Z},
}

@article{almansoori_evolution_2022,
	series = {Communications in {Computer} and {Information} {Science}},
	title = {On the evolution of mechanisms for collective decision making in a swarm of robots: 15th {International} {Workshop} on {Artificial} {Life} and {Evolutionary} {Computation}, {WIVACE} 2021},
	issn = {9783031239281},
	shorttitle = {On the evolution of mechanisms for collective decision making in a swarm of robots},
	url = {http://www.scopus.com/inward/record.url?scp=85148687909&partnerID=8YFLogxK},
	doi = {10.1007/978-3-031-23929-8_11},
	abstract = {Collective decision-making refers to a process of generating a group decision which cannot be attributed to any agent in the group. In swarm robotics, the individual mechanisms for collective decision making are generally hand-designed and limited to a restricted set of solutions based on the voter or the majority model. This study demonstrates that it is possible to take an alternative approach in which the individual mechanisms are implemented using artificial neural network controllers automatically synthesised using evolutionary computation techniques. We qualitatively describe the group dynamics underpinning the collective process leading to consensus. Moreover, this study demonstrates the evolutionary-tailored mechanisms do not follow the principles of the classic hand-coded solutions.},
	urldate = {2025-02-11},
	journal = {Artificial Life and Evolutionary Computation - 15th Italian Workshop, WIVACE 2021, Revised Selected Papers},
	author = {ALMANSOORI, Ahmed and Mohammed, Muhanad Hayder Mohammed and COLIN, Jean-Noel and Tuci, Elio},
	editor = {Schneider, Johannes Josef and Füchslin, Rudolf Marcel and Weyland, Mathias Sebastian and Flumini, Dandolo and Schneider, Johannes Josef and Füchslin, Rudolf Marcel},
	year = {2022},
	note = {Publisher: Springer Science and Business Media Deutschland GmbH},
	keywords = {Automatic design, Collective decision making, Swarm robotics},
	pages = {109--120},
}

@misc{noauthor_public_2024,
	title = {Public defense of doctoral thesis in computer science: {Ahmed} {ALMANSOORI} {\textbar} {UNamur}},
	shorttitle = {Public defense of doctoral thesis in computer science},
	url = {http://www.unamur.be/en/agenda/public-defense-doctoral-thesis-computer-science-ahmed-almansoori},
	language = {en},
	urldate = {2025-02-11},
	month = oct,
	year = {2024},
}

@misc{gctronic_range_nodate,
	title = {Range and {Bearing} {Turret}},
	url = {https://e-puck.gctronic.com/index.php?option=com_content&view=article&id=35&Itemid=23},
	urldate = {2025-02-10},
	author = {{GCtronic}},
}

@misc{gctronic_pi-puck_nodate,
	title = {Pi-puck - {GCtronic} wiki},
	url = {https://www.gctronic.com/doc/index.php?title=Pi-puck},
	urldate = {2025-02-04},
	author = {{GCtronic}},
}

@misc{gctronic_e-puck2_nodate,
	title = {e-puck2 - {GCtronic} wiki},
	url = {https://www.gctronic.com/doc/index.php/e-puck2},
	urldate = {2025-02-04},
	author = {{GCtronic}},
}

@misc{noauthor_e-puck2_nodate,
	title = {e-puck2 {PC} side development - {GCtronic} wiki},
	url = {https://www.gctronic.com/doc/index.php?title=e-puck2_PC_side_development},
	urldate = {2025-02-10},
}

@misc{noauthor_arducam_nodate,
	title = {Arducam {5MP} {OV5647} {Wide} {Angle} 120°({D}) {Miniature} {Camera} {Module} with {Flex} {Cable} for {Pi} {Zero}, {Pi} 5 and {Pi} {Compute} {Module}},
	url = {https://www.arducam.com/product/b006604-arducam-for-raspberry-pi-zero-camera-module-wide-angle-120-1-4-inch-5mp-ov5647-spy-camera-with-flex-cable-for-pi-zero-and-pi-compute-module/},
	abstract = {Supports raspberry pi zero only. For Raspberry Pi Model A/B/B+, Raspberry Pi 2/3/3B+, please search “B0066”  Sensor: 1/4 inch OV5647 sensor in a fixed-focus lens, angle of view: 120° diagonal  Integral IR filter, visible light  Still picture resolution: 2592 x 1944, Max video resolution: 1080p  Dimension: 60mm × 11.5mm × 5.5mm},
	language = {en-US},
	urldate = {2025-02-10},
	journal = {Arducam},
}

@misc{noauthor_software_nodate,
	title = {Software development trends 2021 - {ProQuest}},
	url = {https://www.proquest.com/openview/023eeaa729b6ba2d1133e1b62dffe371/1?pq-origsite=gscholar&cbl=2026675},
	abstract = {Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the ProQuest Platform.},
	language = {en},
	urldate = {2025-02-04},
}

@misc{christian_giang_thymio_nodate,
	title = {{THYMIO} {ESCAPE} {GAME} - {Documentation}},
	url = {https://www.researchgate.net/publication/334460027_THYMIO_ESCAPE_GAME_-_Documentation_EN},
	abstract = {PDF {\textbar} This document describes the preparation and execution of a learning activity with the robot Thymio in the style of an escape game. The activity... {\textbar} Find, read and cite all the research you need on ResearchGate},
	language = {en},
	urldate = {2025-02-04},
	journal = {ResearchGate},
	author = {{Christian Giang}},
}

@misc{christophe_leclere_initiation_2020,
	title = {Initiation {Ludique} {\textbar} {Informatique} de gestion - {Analyste} programmeur},
	shorttitle = {Initiation ludique},
	language = {fr},
	urldate = {2025-02-04},
	publisher = {Hénallux},
	author = {{Christophe Leclère} and {Cécile Pirotte}},
	year = {2020},
}

@misc{noauthor_webots_nodate,
	title = {{WEBOTS} simulator},
	url = {https://e-puck.gctronic.com/index.php?option=com_content&view=article&id=10&Itemid=32},
	urldate = {2025-02-04},
}

@misc{noauthor_v-rep_nodate,
	title = {V-{REP} simulator},
	url = {https://e-puck.gctronic.com/index.php?option=com_content&view=article&id=43&Itemid=39},
	urldate = {2025-02-04},
}

@misc{noauthor_robot_nodate,
	title = {Robot simulator {CoppeliaSim}: create, compose, simulate, any robot - {Coppelia} {Robotics}},
	url = {https://www.coppeliarobotics.com/},
	urldate = {2025-02-04},
}

@misc{noauthor_cyberbotics_nodate,
	title = {Cyberbotics: {Robotics} simulation with {Webots}},
	url = {https://www.cyberbotics.com/},
	urldate = {2025-02-04},
}

@article{batni_current_2025,
	title = {Current {Research} {Trends} of {Scratch} {Block} based {Programming} for {K}-12: {A} {Systematic} {Review}},
	volume = {51},
	copyright = {Copyright (c) 2024 Journal of Advanced Research in Applied Sciences and Engineering Technology},
	issn = {2462-1943},
	shorttitle = {Current {Research} {Trends} of {Scratch} {Block} based {Programming} for {K}-12},
	url = {https://semarakilmu.com.my/journals/index.php/applied_sciences_eng_tech/article/view/2060},
	doi = {10.37934/araset.51.2.138152},
	abstract = {In the evolving landscape of K-12 education, the introduction of programming skills through block-based environments such as Scratch has become increasingly common. This approach meets the growing need for computer literacy among students, but its effectiveness in improving learning outcomes remains controversial. The aim of this paper is to systematically review and summarize current research on the use of Scratch as a teaching and learning tool in K-12 education. Using the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) methodology, this paper analyses 27 relevant articles to assess the impact and use of Scratch in educational settings. The review aims to identify the current trends, methods and foci in Scratch-related educational research. Our results show that 17 studies focus on the use of Scratch in teaching CS and ICT subjects, while 10 examine its application in other academic disciplines. The review shows generally positive results of Scratch programming in an educational context. However, it also highlights the need for more comprehensive empirical research. This includes conducting studies with larger and more diverse student samples over longer periods of time to gain a deeper understanding of how Scratch programming can effectively improve learning outcomes in K-12 education.},
	language = {en},
	number = {2},
	urldate = {2025-02-04},
	journal = {Journal of Advanced Research in Applied Sciences and Engineering Technology},
	author = {Batni, Badruliman and Junaini, Syahrul Nizam and Sidi, Jonathan and Mustafa, Wan Azani and Ismail, Zamhar Iswandono Awang},
	year = {2025},
	note = {Number: 2},
	keywords = {K-12, Teaching, education, learning, scratch},
	pages = {138--152},
}

@misc{noauthor_visual_2025,
	title = {Visual programming language},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Visual_programming_language&oldid=1271498141},
	abstract = {In computing, a visual programming language (visual programming system, VPL, or, VPS), also known as diagrammatic programming, graphical programming or block coding, is a programming language that lets users create programs by manipulating program elements graphically rather than by specifying them textually. A VPL allows programming with visual expressions, spatial arrangements of text and graphic symbols, used either as elements of syntax or secondary notation. For example, many VPLs are based on the idea of "boxes and arrows", where boxes or other screen objects are treated as entities, connected by arrows, lines or arcs which represent relations. VPLs are generally the basis of low-code development platforms.},
	language = {en},
	urldate = {2025-02-03},
	journal = {Wikipedia},
	month = jan,
	year = {2025},
	note = {Page Version ID: 1271498141},
}

@misc{openai_chatgpt_nodate,
	title = {{ChatGPT}},
	url = {https://chatgpt.com},
	abstract = {A conversational AI system that listens, learns, and challenges},
	urldate = {2025-01-28},
	author = {{OpenAI}},
}
